{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Complete Jupyter notebook of my [Blog Post](https://www.nodalpoint.com/transfer-learning-keras/) on how to tranfer learning with keras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.applications import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.callbacks import EarlyStopping\n",
    "import os\n",
    "\n",
    "#path is the path that we save data and dpath the path from where we read data\n",
    "#paths and be path can be the same or not\n",
    "path='/home/'\n",
    "dpath='/var/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelsdf = pd.read_csv(dpath+'labels.csv')\n",
    "ssdf = pd.read_csv(dpath+'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version 3.4.3\n",
      "Tensorflow version 1.1.0\n",
      "Keras version 2.0.4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python version %s.%s.%s\" % sys.version_info[:3])\n",
    "print(\"Tensorflow version %s\" % tf.__version__)\n",
    "print(\"Keras version %s\" % keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read train images and labels\n",
    "train_images_len = labelsdf.shape[0]\n",
    "breed = ssdf.columns[1:]\n",
    "num_class = len(breed)\n",
    "\n",
    "width = 299\n",
    "x_train = np.zeros((train_images_len, width, width, 3), dtype=np.uint8)\n",
    "y_train = np.zeros((train_images_len, num_class), dtype=np.uint8)\n",
    "for i in range(train_images_len):\n",
    "    x_train[i] = cv2.resize(cv2.imread(dpath+'train/%s.jpg' % labelsdf['id'][i]), (width, width), interpolation = cv2.INTER_AREA)\n",
    "    y_train[i][np.where(breed ==  labelsdf['breed'][i])[0][0] ] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#BGR to RGB\n",
    "x_train=x_train[...,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(MODEL, data=x_train):\n",
    "    #Extract Features Function from GlobalAveragePooling2D layer\n",
    "    pretrained_model = MODEL(include_top=False, input_shape=(width, width, 3), weights='imagenet', pooling='avg')\n",
    "    \n",
    "    inputs = Input((width, width, 3))\n",
    "    x = Lambda(preprocess_input, name='preprocessing')(inputs)\n",
    "    outputs = pretrained_model(x)\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    features = model.predict(data, batch_size=64, verbose=1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10222/10222 [==============================] - 132s   \n",
      "10222/10222 [==============================] - 87s    \n",
      "10222/10222 [==============================] - 125s   \n",
      "10222/10222 [==============================] - 79s    \n"
     ]
    }
   ],
   "source": [
    "# Extract features from the original images:\n",
    "x_xception = get_features(Xception, x_train)\n",
    "x_inception = get_features(InceptionV3, x_train)\n",
    "features_train1 = np.concatenate([x_xception, x_inception], axis=-1)\n",
    "\n",
    "# Extract features from flipped images:\n",
    "x_xception = get_features(Xception, np.flip(x_train,axis=2))\n",
    "x_inception = get_features(InceptionV3, np.flip(x_train,axis=2))\n",
    "features_train2 = np.concatenate([x_xception, x_inception], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del x_train\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read test images \n",
    "test_images_len = len(ssdf)\n",
    "x_test = np.zeros((test_images_len, width, width, 3), dtype=np.uint8)\n",
    "for i in range(test_images_len):\n",
    "    x_test[i] = cv2.resize(cv2.imread(dpath+'test/%s.jpg' % ssdf['id'][i]), (width, width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#BGR to RGB\n",
    "x_test=x_test[...,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10357/10357 [==============================] - 150s   \n",
      "10357/10357 [==============================] - 103s   \n",
      "10357/10357 [==============================] - 141s   \n",
      "10357/10357 [==============================] - 83s    \n"
     ]
    }
   ],
   "source": [
    "#Extract Features\n",
    "x_test_xception = get_features(Xception, x_test)                                      \n",
    "x_test_inception = get_features(InceptionV3, x_test)\n",
    "features_test1 = np.concatenate([x_test_xception, x_test_inception], axis=-1)      \n",
    "#Features from flipped images\n",
    "x_test_xception = get_features(Xception, np.flip(x_test,axis=2))                                      \n",
    "x_test_inception = get_features(InceptionV3, np.flip(x_test,axis=2))\n",
    "features_test2 = np.concatenate([x_test_xception, x_test_inception], axis=-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#5 fold predictions with horizontal image flips\n",
    "allrows=([x for x in range(features_train1.shape[0])])\n",
    "trainpreds=np.zeros((features_train1.shape[0],120))\n",
    "testpreds=np.zeros((features_test1.shape[0],120))\n",
    "callbacks = [EarlyStopping(monitor='val_loss',  patience=3, verbose=1)]\n",
    "\n",
    "input_shape = features_train1.shape[1:]\n",
    "for i in range(5):\n",
    "    inputs = Input(input_shape)\n",
    "    x = Dropout(0.5)(inputs)\n",
    "    outputs = Dense(num_class, activation='softmax')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='Adagrad', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    inputs = Input(input_shape)\n",
    "    x = Dropout(0.5)(inputs)\n",
    "    outputs = Dense(num_class, activation='softmax')(x)\n",
    "    model2 = Model(inputs, outputs)\n",
    "    model2.compile(optimizer='Adagrad', loss='categorical_crossentropy', metrics=['accuracy'])    \n",
    "    if i !=4:\n",
    "        valrows=([x for x in range(2044*i,2044*(i+1))])\n",
    "        trainrows=([x for x in allrows if x not in valrows])\n",
    "\n",
    "    else:\n",
    "        valrows=([x for x in range(2044*i,features_train1.shape[0])])\n",
    "        trainrows=np.array([x for x in allrows if x not in valrows])        \n",
    "        \n",
    "    h = model.fit(features_train1[trainrows,:], y_train[trainrows,:], batch_size=128, epochs=50, \n",
    "              validation_data=(features_train1[valrows,:], y_train[valrows,:]), callbacks=callbacks)\n",
    "    h2 = model2.fit(features_train2[trainrows,:], y_train[trainrows,:], batch_size=128, epochs=50, \n",
    "              validation_data=(features_train2[valrows,:], y_train[valrows,:]), callbacks=callbacks)\n",
    "    \n",
    "    y_pred_train = model.predict(features_train1[valrows,:], batch_size=128)\n",
    "    y_pred_train += model2.predict(features_train2[valrows,:], batch_size=128)\n",
    "    trainpreds[valrows,:]=y_pred_train/2\n",
    "    y_pred = model.predict(features_test1, batch_size=128)\n",
    "    y_pred2 = model2.predict(features_test2, batch_size=128)\n",
    "    testpreds += (y_pred+y_pred2)/2\n",
    "testpreds/=5    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create submission file\n",
    "for b in ssdf.columns[1:]:\n",
    "    ssdf[b] = testpreds[:,np.where(breed == b)[0][0]]\n",
    "ssdf.to_csv('XceptInceptSubmissionWithFlips.csv', index=None)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
